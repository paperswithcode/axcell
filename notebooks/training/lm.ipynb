{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Pre-training\n",
    "\n",
    "This notebook presents how to pretrain ULMFiT language model on the **ArxivPapers** dataset. You can download the pretrained model at https://github.com/paperswithcode/axcell/releases/download/v1.0/lm.pth.xz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BPTT = 80\n",
    "VOCAB_SIZE = 30000\n",
    "UNIGRAM_MODEL_SENTENCES = 5000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axcell.data.paper_collection import PaperCollection\n",
    "from pathlib import Path\n",
    "\n",
    "# path to extracted papers from ArxivPapers dataset\n",
    "PAPERS_PATH = Path('./data/arxiv-papers/papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 11.3 s, total: 3min\n",
      "Wall time: 5min 46s\n"
     ]
    }
   ],
   "source": [
    "%time pc = PaperCollection.from_files(PAPERS_PATH, load_tables=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axcell.helpers.datasets import read_arxiv_papers\n",
    "\n",
    "V1_URL = 'https://github.com/paperswithcode/axcell/releases/download/v1.0/'\n",
    "ARXIV_PAPERS_URL = V1_URL + 'arxiv-papers.csv.xz'\n",
    "arxiv_papers = read_arxiv_papers(ARXIV_PAPERS_URL)\n",
    "\n",
    "assert len(pc) == (arxiv_papers.status == 'success').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "anchors_re = re.compile(r\"xxanchor-[^ ]*\")\n",
    "refs_re = re.compile(r\"xxref-[^ ]*\")\n",
    "\n",
    "\n",
    "def remove_anchors(s):\n",
    "    return anchors_re.sub(\"\", s)\n",
    "\n",
    "def replace_references(s):\n",
    "    return refs_re.sub(\"xxref\", s)\n",
    "\n",
    "def clean_text(s):\n",
    "    s = remove_anchors(s)\n",
    "    s = replace_references(s)\n",
    "    return s\n",
    "\n",
    "def get_texts(pc):\n",
    "    texts = []\n",
    "    for p in sorted(pc, key=lambda p: p.paper_id):\n",
    "        # do not include empty texts\n",
    "        if not hasattr(p.text, \"fragments\"):\n",
    "            continue\n",
    "        header = f\"Title\\n{p.text.title}\\n\\nAbstract\\n{p.text.abstract}\\n\\nBody\\n\"\n",
    "        last_section = None\n",
    "        fragments = []\n",
    "        for f in p.text.fragments:\n",
    "            if last_section != f.header:\n",
    "                fragments.append(f.header+\"\\n\")\n",
    "                last_section = f.header\n",
    "            fragments.append(f.text)\n",
    "        text = header + '\\n'.join(fragments)\n",
    "        text = clean_text(text)\n",
    "        texts.append(text)\n",
    "    return pd.DataFrame({'text': texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 3.19 s, total: 1min 28s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%time texts = get_texts(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n",
      "VQA-LOL: Visual Question Answering under the Lens of Logic\n",
      "\n",
      "Abstract\n",
      "Logical connectives and t...\n"
     ]
    }
   ],
   "source": [
    "print(texts.text.iloc[-1][:100]+'...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts.to_pickle(\"/data/arxiv/dumps/arxiv-papers-texts-dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pd.read_pickle(\"/data/arxiv/dumps/arxiv-papers-texts-dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce number of sentences to avoid sentencepiece badalloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    sentence\n",
    "    for text in texts.text.values\n",
    "    for sentence in text.split('\\n')\n",
    "    if sentence.strip()\n",
    "]\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "indices = np.random.choice(range(len(sentences)), size=UNIGRAM_MODEL_SENTENCES, replace=False)\n",
    "sentences = [sentences[index] for index in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "\n",
    "BASE_PATH = Path('./models')\n",
    "BASE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processor = SPProcessor(vocab_sz=VOCAB_SIZE, mark_fields=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 40min 51s, sys: 36.1 s, total: 1h 41min 27s\n",
      "Wall time: 41min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('models/tmp')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time processor.train_func(sentences, BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SPProcessor(sp_model=BASE_PATH / \"tmp\" / \"spm.model\", sp_vocab=BASE_PATH / \"tmp\" / \"spm.vocab\", mark_fields=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 29s, sys: 51 s, total: 18min 20s\n",
      "Wall time: 26min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_lm = (\n",
    "    TextList.from_df(\n",
    "        texts, BASE_PATH, cols=\"text\", processor=processor\n",
    "    ).split_by_rand_pct(0.1, seed=12345)\n",
    "     .label_for_lm()\n",
    "     .databunch(bs=BATCH_SIZE, bptt=BPTT)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_lm.save('arxiv-papers-texts-data_lm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "data_lm = load_data(BASE_PATH, 'arxiv-papers-texts-data_lm.pkl', bs=BATCH_SIZE, bptt=BPTT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.019458</td>\n",
       "      <td>3.264306</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>26.161938</td>\n",
       "      <td>1:54:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.056603</td>\n",
       "      <td>3.422664</td>\n",
       "      <td>0.376507</td>\n",
       "      <td>30.651068</td>\n",
       "      <td>1:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.141768</td>\n",
       "      <td>3.550231</td>\n",
       "      <td>0.362796</td>\n",
       "      <td>34.821327</td>\n",
       "      <td>1:53:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.090492</td>\n",
       "      <td>3.525985</td>\n",
       "      <td>0.366870</td>\n",
       "      <td>33.987396</td>\n",
       "      <td>1:53:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.107407</td>\n",
       "      <td>3.491773</td>\n",
       "      <td>0.370532</td>\n",
       "      <td>32.844139</td>\n",
       "      <td>1:54:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.059378</td>\n",
       "      <td>3.445549</td>\n",
       "      <td>0.375365</td>\n",
       "      <td>31.360525</td>\n",
       "      <td>1:54:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.030591</td>\n",
       "      <td>3.368207</td>\n",
       "      <td>0.382388</td>\n",
       "      <td>29.026358</td>\n",
       "      <td>1:53:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.965446</td>\n",
       "      <td>3.278792</td>\n",
       "      <td>0.391360</td>\n",
       "      <td>26.543692</td>\n",
       "      <td>1:53:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.919746</td>\n",
       "      <td>3.163137</td>\n",
       "      <td>0.404793</td>\n",
       "      <td>23.644709</td>\n",
       "      <td>1:53:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.812866</td>\n",
       "      <td>3.019272</td>\n",
       "      <td>0.421912</td>\n",
       "      <td>20.476440</td>\n",
       "      <td>1:53:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.800652</td>\n",
       "      <td>2.874423</td>\n",
       "      <td>0.440786</td>\n",
       "      <td>17.715170</td>\n",
       "      <td>1:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.870245</td>\n",
       "      <td>2.789970</td>\n",
       "      <td>0.453570</td>\n",
       "      <td>16.280558</td>\n",
       "      <td>1:53:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(\n",
    "    data_lm, AWD_LSTM, drop_mult=0.1,\n",
    "    pretrained=False, metrics=[accuracy, Perplexity()]\n",
    ").to_fp16(clip=0.1)\n",
    "\n",
    "learn.fit_one_cycle(cyc_len=12, max_lr=0.01, moms=(0.8, 0.7), div_factor=10, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('pretrained-on-papers_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('pretrained-on-papers_learner_with_opt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
